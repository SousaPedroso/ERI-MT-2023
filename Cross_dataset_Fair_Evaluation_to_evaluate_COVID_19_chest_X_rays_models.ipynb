{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKvlLTyRN1Ak",
        "outputId": "c9675cdc-6d97-49d7-f986-17c2b3919dd3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import threading\n",
        "\n",
        "import urllib.request\n",
        "import requests\n",
        "\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "import sklearn\n",
        "import sklearn.preprocessing\n",
        "import sklearn.model_selection\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# Set seed for reprodutibility\n",
        "seed=1\n",
        "tf.keras.utils.set_random_seed(seed)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41mNdiocdRWO"
      },
      "source": [
        "## Definição da Forma de Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A40Jp6nvaYfr"
      },
      "source": [
        "Dadas as 2 bases iniciais, e 2 modelos inicias, será selecionado um modelo para cada iteração de folds\n",
        "\n",
        "Para cada base, será necessário realizar cross-validation com 5 folds. Haverá a junção das 3 bases para realizar o treinamento, os quais serão validados depois\n",
        "\n",
        "Após os 5 folds para o modelo, serão realizados isso para o outro modelo. Por último, será realizado o teste com o Resnet\n",
        "\n",
        "O que foi descrito acima será realizado com o uso de metadados para a especificação de subclasses com as classes já existentes dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9uybuRsSD85"
      },
      "source": [
        "## Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "684xFhTGQQxg"
      },
      "source": [
        "### Cohen dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMogDOeBQR0s",
        "outputId": "1be63ea9-6471-445c-ab79-3600a169d2b5"
      },
      "outputs": [],
      "source": [
        "cohen_dir  = \"cohen_dataset/\"\n",
        "if not os.path.exists(cohen_dir):\n",
        "  os.mkdir(cohen_dir)\n",
        "cohen_url = \"https://api.github.com/repos/ieee8023/covid-chestxray-dataset/contents/images\"\n",
        "images_requisition = list(requests.get(cohen_url).json())\n",
        "files = []\n",
        "# Divide para cada uma das 24 threads a imagem para baixar\n",
        "total_images = len(images_requisition)\n",
        "images_per_thread = total_images//24\n",
        "\n",
        "def download_images(images, begining, stop):\n",
        "  for moment in range(begining, stop):\n",
        "    files.append(images[moment]['download_url'])\n",
        "    urllib.request.urlretrieve(images[moment]['download_url'], os.path.join(cohen_dir, images[moment]['name']))\n",
        "\n",
        "threads = [threading.Thread(target=download_images, args=(images_requisition, i*images_per_thread, i*images_per_thread+images_per_thread)) if i != 23\n",
        "           else threading.Thread(target=download_images, args=(images_requisition, i*images_per_thread, i*images_per_thread+images_per_thread+total_images%24))\n",
        "           for i in range(24)]\n",
        "\n",
        "for thread in threads:\n",
        "  thread.start()\n",
        "\n",
        "for thread in threads:\n",
        "  thread.join()\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ieee8023/covid-chestxray-dataset/master/metadata.csv\", \"cohen_metadata.csv\")\n",
        "\n",
        "cohen_metadata = pd.read_csv(\"cohen_metadata.csv\")\n",
        "cohen_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4y1x5k_APxt"
      },
      "source": [
        "### Kag dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yKtXQt9TDg4"
      },
      "source": [
        "Substitua onde está CREDENCIAIS_DE_ACESSO pela pasta que contém suas credenciais do Kaggle. Fique livre para manter onde está, ignorando as 4 primeiras linhas e trocando a pasta /root/.kaggle/kaggle.json pela localização de suas credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaAg-tiwGvO9",
        "outputId": "b311fff0-ae88-47ec-ab08-3a91d3c167b2"
      },
      "outputs": [],
      "source": [
        "!cp CREDENCIAIS_DE_ACESSO ./\n",
        "!rm /root/.kaggle\n",
        "!mkdir /root/.kaggle\n",
        "!mv ./kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download --unzip paultimothymooney/chest-xray-pneumonia\n",
        "!rename 's/chest_xray/kag_dataset/' *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eD5ZAcqVg10"
      },
      "source": [
        "## Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJTky4CMrJP2"
      },
      "outputs": [],
      "source": [
        "img_height, img_width = 224, 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "larS7w2nRcEF"
      },
      "source": [
        "Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mESxvLLCReBC",
        "outputId": "11d43abc-c30e-4581-8b70-9e44a0639774"
      },
      "outputs": [],
      "source": [
        "# O mapeamento de classes mudará de base para base, mas manteremos um padrão\n",
        "# para cada doença ou se a pessoa está saudável\n",
        "\n",
        "# kag x Cohen\n",
        "categories = ['kag_normal', 'kag_pneumonia_bacteria', 'kag_pneumonia_virus',\n",
        "              'cohen_covid19', 'cohen_other_virus', 'cohen_bacteria', 'cohen_fungal']\n",
        "\n",
        "le = sklearn.preprocessing.LabelEncoder()\n",
        "le_categories = le.fit_transform(categories)\n",
        "le_categories = le_categories.reshape(len(le_categories), 1)\n",
        "\n",
        "ohe = sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
        "ohe.fit(le_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaqOH3Y3EAIO"
      },
      "source": [
        "### COHEN dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz6awaRAsy06"
      },
      "source": [
        "Será distinguida a covid de outros vírus, com as outras classes se agrupando por reino animal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWax-NSFs87w"
      },
      "outputs": [],
      "source": [
        "# X-ray images\n",
        "cohen_xray_metada = cohen_metadata[cohen_metadata['modality'] == 'X-ray']\n",
        "covid_19_metadata = cohen_xray_metada[cohen_xray_metada['finding'] == 'Pneumonia/Viral/COVID-19']\n",
        "# Procurar outros vírus E acelerar para a busca das outras classes\n",
        "other_metadata = cohen_xray_metada[cohen_xray_metada['finding'] != 'Pneumonia/Viral/COVID-19']\n",
        "\n",
        "other_virus_metadata = other_metadata[other_metadata['finding'].str.startswith('Pneumonia/Viral')]\n",
        "bacterial_metadata = other_metadata[other_metadata['finding'].str.startswith('Pneumonia/Bacterial')]\n",
        "fungal_metadata = other_metadata[other_metadata['finding'].str.startswith('Pneumonia/Fungal')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBOfTLUoAeJE"
      },
      "source": [
        "#### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqgSdairKDFl",
        "outputId": "17ad1a77-2e4d-4479-88f3-89be8127f1a9"
      },
      "outputs": [],
      "source": [
        "cohen_xray_metada['finding'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsCnw0j_7Kv9"
      },
      "outputs": [],
      "source": [
        "cohen_x_dataset = []\n",
        "cohen_y_dataset = []\n",
        "cohen_dir = \"cohen_dataset\"\n",
        "\n",
        "# Acelerar comparação\n",
        "covid_found = 0\n",
        "other_virus_found = 0\n",
        "bacterial_found = 0\n",
        "fungal_found = 0\n",
        "total_images = len(covid_19_metadata)+len(other_virus_metadata)+len(bacterial_metadata)+len(fungal_metadata)\n",
        "\n",
        "# Procura nos metadados as imagens necessárias\n",
        "training_data_filenames = os.listdir(cohen_dir)\n",
        "for img_name in training_data_filenames:\n",
        "  if covid_found+other_virus_found+bacterial_found+fungal_found != total_images:\n",
        "\n",
        "    if covid_found != len(covid_19_metadata) and len(covid_19_metadata[covid_19_metadata['filename'].isin([img_name])])!=0:\n",
        "      covid_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_covid19'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif other_virus_found != len(other_virus_metadata) and len(other_virus_metadata[other_virus_metadata['filename'].isin([img_name])])!=0:\n",
        "      other_virus_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_other_virus'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif bacterial_found != len(bacterial_metadata) and len(bacterial_metadata[bacterial_metadata['filename'].isin([img_name])])!=0:\n",
        "      bacterial_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_bacteria'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif fungal_found != len(fungal_metadata) and len(fungal_metadata[fungal_metadata['filename'].isin([img_name])])!=0:\n",
        "      fungal_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_fungal'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "    with PIL.Image.open(os.path.join(cohen_dir, img_name)) as img:\n",
        "      PIL.ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "      img_resized = img.convert('L')\n",
        "      img_resized = img_resized.resize((img_width, img_height))\n",
        "      cohen_x_dataset.append(np.reshape(np.asarray(img_resized), (img_width, img_height, 1)))\n",
        "\n",
        "  # Achou todas as classes precisas\n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHNcAOBCoMgw"
      },
      "source": [
        "#### Separação de visualizações (PA, AP, AP Supine e L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCfTUBmRoUH4"
      },
      "source": [
        "ANTEROPOSTERIOR, POSTOANTERIOR, AP SUPINO e Lateral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys_yQx6V8jn6"
      },
      "outputs": [],
      "source": [
        "covid_19_ap_metadata = covid_19_metadata[covid_19_metadata['view'] == 'AP']\n",
        "covid_19_pa_metadata = covid_19_metadata[covid_19_metadata['view'] == 'PA']\n",
        "covid_19_ap_supine_metadata = covid_19_metadata[covid_19_metadata['view'] == 'AP Supine']\n",
        "covid_19_l_metadata = covid_19_metadata[covid_19_metadata['view'] == 'L']\n",
        "\n",
        "other_virus_ap_metadata = other_virus_metadata[other_virus_metadata['view'] == 'AP']\n",
        "other_virus_pa_metadata = other_virus_metadata[other_virus_metadata['view'] == 'PA']\n",
        "other_virus_ap_supine_metadata = other_virus_metadata[other_virus_metadata['view'] == 'AP Supine']\n",
        "other_virus_l_metadata = other_virus_metadata[other_virus_metadata['view'] == 'L']\n",
        "\n",
        "bacterial_ap_metadata = bacterial_metadata[bacterial_metadata['view'] == 'AP']\n",
        "bacterial_pa_metadata = bacterial_metadata[bacterial_metadata['view'] == 'PA']\n",
        "bacterial_l_metadata = bacterial_metadata[bacterial_metadata['view'] == 'L']\n",
        "bacterial_ap_supine_metadata = bacterial_metadata[bacterial_metadata['view'] == 'AP Supine']\n",
        "\n",
        "fungal_ap_metadata = fungal_metadata[fungal_metadata['view'] == 'AP']\n",
        "fungal_pa_metadata = fungal_metadata[fungal_metadata['view'] == 'AP']\n",
        "fungal_ap_supine_metadata = fungal_metadata[fungal_metadata['view'] == 'AP']\n",
        "fungal_l_metadata = fungal_metadata[fungal_metadata['view'] == 'AP']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j86xKVUyBDCI"
      },
      "source": [
        "Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA0bbdp1oSTH",
        "outputId": "3a0ce688-312b-422b-b99e-eb30d1de47fa"
      },
      "outputs": [],
      "source": [
        "# O mapeamento de classes mudará de base para base, mas manteremos um padrão\n",
        "# para cada doença ou se a pessoa está saudável\n",
        "\n",
        "# kag x Cohen\n",
        "categories = ['kag_normal', 'kag_pneumonia_bacteria', 'kag_pneumonia_virus',\n",
        "              'cohen_ap_covid19', 'cohen_ap_other_virus', 'cohen_ap_bacterial', 'cohen_ap_fungal',\n",
        "              'cohen_pa_covid19', 'cohen_pa_other_virus', 'cohen_pa_bacterial', 'cohen_pa_fungal',\n",
        "              'cohen_l_covid19', 'cohen_l_other_virus', 'cohen_l_bacterial', 'cohen_l_fungal',\n",
        "              'cohen_ap_supine_covid19', 'cohen_ap_supine_other_virus', 'cohen_ap_supine_bacterial', 'cohen_ap_supine_fungal']\n",
        "\n",
        "le = sklearn.preprocessing.LabelEncoder()\n",
        "le_categories = le.fit_transform(categories)\n",
        "le_categories = le_categories.reshape(len(le_categories), 1)\n",
        "\n",
        "ohe = sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
        "ohe.fit(le_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBuzgAyMCBkq"
      },
      "source": [
        "Find labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPy00lLHCD2z"
      },
      "outputs": [],
      "source": [
        "cohen_x_dataset = []\n",
        "cohen_y_dataset = []\n",
        "cohen_dir = \"cohen_dataset\"\n",
        "\n",
        "# Acelerar comparação\n",
        "covid_found = 0\n",
        "other_virus_found = 0\n",
        "bacterial_found = 0\n",
        "fungal_found = 0\n",
        "total_images = len(covid_19_metadata)+len(other_virus_metadata)+len(bacterial_metadata)+len(fungal_metadata)\n",
        "\n",
        "# Procura nos metadados as imagens necessárias\n",
        "training_data_filenames = os.listdir(cohen_dir)\n",
        "for img_name in training_data_filenames:\n",
        "  if covid_found+other_virus_found+bacterial_found+fungal_found != total_images:\n",
        "\n",
        "    if covid_found != len(covid_19_metadata) and len(covid_19_ap_metadata[covid_19_ap_metadata['filename'].isin([img_name])])!=0:\n",
        "      covid_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_covid19'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif covid_found != len(covid_19_metadata) and len(covid_19_pa_metadata[covid_19_pa_metadata['filename'].isin([img_name])])!=0:\n",
        "      covid_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_pa_covid19'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif covid_found != len(covid_19_metadata) and len(covid_19_ap_supine_metadata[covid_19_ap_supine_metadata['filename'].isin([img_name])])!=0:\n",
        "      covid_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_supine_covid19'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif covid_found != len(covid_19_metadata) and len(covid_19_l_metadata[covid_19_l_metadata['filename'].isin([img_name])])!=0:\n",
        "      covid_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_l_covid19'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif other_virus_found != len(other_virus_metadata) and len(other_virus_ap_metadata[other_virus_ap_metadata['filename'].isin([img_name])])!=0:\n",
        "      other_virus_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_other_virus'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif other_virus_found != len(other_virus_metadata) and len(other_virus_pa_metadata[other_virus_pa_metadata['filename'].isin([img_name])])!=0:\n",
        "      other_virus_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_pa_other_virus'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif other_virus_found != len(other_virus_metadata) and len(other_virus_ap_supine_metadata[other_virus_ap_supine_metadata['filename'].isin([img_name])])!=0:\n",
        "      other_virus_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_supine_other_virus'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif other_virus_found != len(other_virus_metadata) and len(other_virus_l_metadata[other_virus_l_metadata['filename'].isin([img_name])])!=0:\n",
        "      other_virus_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_l_other_virus'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif bacterial_found != len(bacterial_metadata) and len(bacterial_ap_metadata[bacterial_ap_metadata['filename'].isin([img_name])])!=0:\n",
        "      bacterial_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_bacterial'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif bacterial_found != len(bacterial_metadata) and len(bacterial_pa_metadata[bacterial_pa_metadata['filename'].isin([img_name])])!=0:\n",
        "      bacterial_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_pa_bacterial'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif bacterial_found != len(bacterial_metadata) and len(bacterial_ap_supine_metadata[bacterial_ap_supine_metadata['filename'].isin([img_name])])!=0:\n",
        "      bacterial_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_supine_bacterial'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif bacterial_found != len(bacterial_metadata) and len(bacterial_l_metadata[bacterial_l_metadata['filename'].isin([img_name])])!=0:\n",
        "      bacterial_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_l_bacterial'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif fungal_found != len(fungal_metadata) and len(fungal_ap_metadata[fungal_ap_metadata['filename'].isin([img_name])])!=0:\n",
        "      fungal_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_fungal'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif fungal_found != len(fungal_metadata) and len(fungal_pa_metadata[fungal_pa_metadata['filename'].isin([img_name])])!=0:\n",
        "      fungal_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_pa_fungal'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif fungal_found != len(fungal_metadata) and len(fungal_ap_supine_metadata[fungal_ap_supine_metadata['filename'].isin([img_name])])!=0:\n",
        "      fungal_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_ap_supine_fungal'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    elif fungal_found != len(fungal_metadata) and len(fungal_l_metadata[fungal_l_metadata['filename'].isin([img_name])])!=0:\n",
        "      fungal_found += 1\n",
        "      cohen_y_dataset.append(ohe.transform([le.transform(['cohen_l_fungal'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "    with PIL.Image.open(os.path.join(cohen_dir, img_name)) as img:\n",
        "      img_resized = img.convert('L')\n",
        "      img_resized = img_resized.resize((img_width, img_height))\n",
        "      cohen_x_dataset.append(np.reshape(np.asarray(img_resized), (img_width, img_height, 1)))\n",
        "\n",
        "  # Achou todas as classes precisas\n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxOBp6y1ED9D"
      },
      "source": [
        "### Kag dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQxDikOrY2lx"
      },
      "outputs": [],
      "source": [
        "def find_class_label(image_name):\n",
        "  expression = re.findall(r'person\\d*_(bacteria|virus)_\\d*', image_name, flags=re.I)\n",
        "  label = expression[0].lower()\n",
        "\n",
        "  return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGXltPd_EGY1"
      },
      "outputs": [],
      "source": [
        "# kag_dataset = []\n",
        "kag_dir = \"kag_dataset\"\n",
        "gc.collect()\n",
        "\n",
        "kag_x_train = []\n",
        "kag_x_val = []\n",
        "kag_y_train = []\n",
        "kag_y_val = []\n",
        "\n",
        "kag_train_dir = os.path.join(kag_dir, \"train\")\n",
        "for finding in os.listdir(kag_train_dir):\n",
        "  finding_path = os.path.join(kag_train_dir, finding)\n",
        "  for image in os.listdir(finding_path):\n",
        "    with PIL.Image.open(os.path.join(finding_path, image)) as img:\n",
        "      img_resized = img.convert('L')\n",
        "      img_resized = img_resized.resize((img_width, img_height))\n",
        "      kag_x_train.append(np.reshape(np.asarray(img_resized), (img_width, img_height, 1)))\n",
        "\n",
        "    if finding == 'NORMAL':\n",
        "      kag_y_train.append(ohe.transform([le.transform(['kag_normal'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "    else:\n",
        "      label = find_class_label(image)\n",
        "      kag_y_train.append(ohe.transform([le.transform([f'kag_pneumonia_{label}'])]).reshape(len(le_categories), 1))\n",
        "\n",
        "kag_val_dir = os.path.join(kag_dir, \"test\")\n",
        "for finding in os.listdir(kag_val_dir):\n",
        "  finding_path = os.path.join(kag_val_dir, finding)\n",
        "  for image in os.listdir(finding_path):\n",
        "    with PIL.Image.open(os.path.join(finding_path, image)) as img:\n",
        "      img_resized = img.convert('L')\n",
        "      img_resized = img_resized.resize((img_width, img_height))\n",
        "      kag_x_val.append(np.reshape(np.asarray(img_resized), (img_width, img_height, 1)))\n",
        "\n",
        "    if finding == 'NORMAL':\n",
        "      kag_y_val.append(ohe.transform([le.transform(['kag_normal'])]).reshape(len(le_categories), 1))\n",
        "    else:\n",
        "      label = find_class_label(image)\n",
        "      kag_y_val.append(ohe.transform([le.transform([f'kag_pneumonia_{label}'])]).reshape(len(le_categories), 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtJPK8Ezcovw"
      },
      "source": [
        "## Definição dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eN_XMMp9hSB"
      },
      "outputs": [],
      "source": [
        "classes_number = len(categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGKvs2ZxYZaJ"
      },
      "source": [
        "Model for extract different segments for larger regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEGGbsuPVplI"
      },
      "outputs": [],
      "source": [
        "different_segments_model = [\n",
        "    tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 1)),\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "    tf.keras.layers.Dropout(0.2, seed=seed),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.2, seed=seed),\n",
        "    tf.keras.layers.Dense(128, activation='relu')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymerkZqRYdBu"
      },
      "source": [
        "Model to extract low-level to high-level features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufet5ENRYgR7"
      },
      "outputs": [],
      "source": [
        "high_level_low_level_model = [\n",
        "    tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 1)),\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2, seed=seed),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(padding='valid'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.2, seed=seed),\n",
        "    tf.keras.layers.Dense(128, activation='relu')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbIZLz1aSI1Z"
      },
      "source": [
        "Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0lB3lZeSKZO",
        "outputId": "67ea154c-de9e-4ed7-f442-184c21307678"
      },
      "outputs": [],
      "source": [
        "input_tensor = tf.keras.layers.Input(shape=(img_height, img_width, 3))\n",
        "resnet50 = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet',\n",
        "                                                   input_tensor=input_tensor, input_shape=(img_height,img_width, 3))\n",
        "\n",
        "for layer in resnet50.layers[:]:\n",
        "   layer.trainable = False\n",
        "\n",
        "output = resnet50.output\n",
        "output = tf.keras.layers.Flatten()(output)\n",
        "output = tf.keras.layers.Dense(classes_number, activation='softmax')(output)\n",
        "\n",
        "resnet50 = tf.keras.Model(inputs=resnet50.input, outputs=output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBA7Ny8oZcYN"
      },
      "source": [
        "## Uso do protocolo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvKa_MxBQ6nC"
      },
      "source": [
        "Substitua a variável por onde deseja salvar as métricas e os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3bn5u2ghgvC"
      },
      "outputs": [],
      "source": [
        "experiments_path = \"\"\n",
        "# Hiperparâmetros e parâmetros\n",
        "batch_size = 64\n",
        "lr=1e-3\n",
        "epochs=15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3it-HPN8zKp"
      },
      "source": [
        "### cohen dataset e kag dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jkiegIKfpHl"
      },
      "source": [
        "#### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPjqKi1DA85S"
      },
      "outputs": [],
      "source": [
        "cohen_x_train, cohen_x_test, cohen_y_train, cohen_y_test = sklearn.model_selection.train_test_split(cohen_x_dataset, cohen_y_dataset, test_size=0.1, random_state=seed)\n",
        "cohen_x_train, cohen_x_val, cohen_y_train, cohen_y_val = sklearn.model_selection.train_test_split(cohen_x_train, cohen_y_train, train_size=0.78, random_state=seed)\n",
        "\n",
        "X_train = np.concatenate((cohen_x_train, kag_x_train))\n",
        "X_val = np.concatenate((cohen_x_val, kag_x_val))\n",
        "\n",
        "y_train = np.concatenate((cohen_y_train, kag_y_train))\n",
        "y_train =  y_train.reshape(y_train.shape[0], y_train.shape[1])\n",
        "\n",
        "y_val = np.concatenate((cohen_y_val, kag_y_val))\n",
        "y_val =  y_val.reshape(y_val.shape[0], y_val.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ooq7t5ab3JZ",
        "outputId": "9341c5f7-75e4-4ca5-9852-f092186c3aed"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential(resnet50, name=\"resnet50\")\n",
        "\n",
        "# Converter os dados para 3 canais\n",
        "X_train = np.concatenate((X_train, X_train, X_train), axis=-1)\n",
        "X_val = np.concatenate((X_val, X_val, X_val), axis=-1)\n",
        "\n",
        "history_baseline_cohen_kag = 'baseline_cohen_kag'\n",
        "output_path = os.path.join(experiments_path, f\"{history_baseline_cohen_kag}_{model.name}\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBewR9tgcAN4"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8IRSnJMlJUh"
      },
      "outputs": [],
      "source": [
        "model.save(output_path, save_format='h5')\n",
        "df = pd.DataFrame(history.history)\n",
        "df.to_csv(os.path.join(experiments_path, f\"{history_baseline_cohen_kag}_{model.name}.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H9YvIvPfzBy"
      },
      "source": [
        "#### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyAVfQT8fyjy"
      },
      "outputs": [],
      "source": [
        "kag_test_dir = os.path.join(kag_dir, \"val\")\n",
        "kag_x_test = []\n",
        "kag_y_test = []\n",
        "\n",
        "for finding in os.listdir(kag_val_dir):\n",
        "  finding_path = os.path.join(kag_val_dir, finding)\n",
        "  for image in os.listdir(finding_path):\n",
        "    with PIL.Image.open(os.path.join(finding_path, image)) as img:\n",
        "      img_resized = img.convert('L')\n",
        "      img_resized = img_resized.resize((img_width, img_height))\n",
        "      kag_x_test.append(np.reshape(np.asarray(img_resized), (img_width, img_height, 1)))\n",
        "\n",
        "    if finding == 'NORMAL':\n",
        "      kag_y_test.append(ohe.transform([le.transform(['kag_normal'])]).reshape(len(le_categories), 1))\n",
        "    else:\n",
        "      label = find_class_label(image)\n",
        "      kag_y_test.append(ohe.transform([le.transform([f'kag_pneumonia_{label}'])]).reshape(len(le_categories), 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fCuM_IwMxV"
      },
      "source": [
        "##### Larger regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPC_iEhGf3iD",
        "outputId": "7b11709d-901e-49d6-b2c3-f46fc6199a55"
      },
      "outputs": [],
      "source": [
        "cohen_kag_x_dataset = np.concatenate((cohen_x_dataset, kag_x_train, kag_x_val, kag_x_test))\n",
        "cohen_kag_y_dataset = np.concatenate((cohen_y_dataset, kag_y_train, kag_y_val, kag_y_test))\n",
        "cohen_kag_y_dataset = cohen_kag_y_dataset.reshape(cohen_kag_y_dataset.shape[0], cohen_kag_y_dataset.shape[1])\n",
        "\n",
        "cohen_kag_x_dataset, X_test, cohen_kag_y_dataset, y_test = sklearn.model_selection.train_test_split(cohen_kag_x_dataset, cohen_kag_y_dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "cv = sklearn.model_selection.ShuffleSplit(n_splits=5, train_size=0.78, random_state=seed)\n",
        "history_cross_cohen_kag = 'cv_cohen_kag'\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in cv.split(cohen_kag_x_dataset):\n",
        "  X_train, y_train = cohen_kag_x_dataset[train_index], cohen_kag_y_dataset[train_index]\n",
        "  X_val, y_val = cohen_kag_x_dataset[val_index], cohen_kag_y_dataset[val_index]\n",
        "\n",
        "  model = tf.keras.models.Sequential(different_segments_model+\n",
        "                                    [tf.keras.layers.Dense(classes_number, activation='softmax')], name=\"larger_regions\")\n",
        "\n",
        "  output_path = os.path.join(experiments_path, f\"{history_cross_cohen_kag}_iteration_{i}_{model.name}\")\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)\n",
        "  model.save(output_path, save_format='h5')\n",
        "  df = pd.DataFrame(history.history)\n",
        "  df.to_csv(f\"{output_path}.csv\")\n",
        "  i+= 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX0foXrTtapT"
      },
      "source": [
        "##### Low-level to high-level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhvNNtHxtZ9j",
        "outputId": "783a9e2d-ad7d-4044-b8a8-6c57b25096dd"
      },
      "outputs": [],
      "source": [
        "cohen_kag_x_dataset = np.concatenate((cohen_x_dataset, kag_x_train, kag_x_val, kag_x_test))\n",
        "cohen_kag_y_dataset = np.concatenate((cohen_y_dataset, kag_y_train, kag_y_val, kag_y_test))\n",
        "cohen_kag_y_dataset = cohen_kag_y_dataset.reshape(cohen_kag_y_dataset.shape[0], cohen_kag_y_dataset.shape[1])\n",
        "\n",
        "cohen_kag_x_dataset, X_test, cohen_kag_y_dataset, y_test = sklearn.model_selection.train_test_split(cohen_kag_x_dataset, cohen_kag_y_dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "cv = sklearn.model_selection.ShuffleSplit(n_splits=5, train_size=0.78, random_state=seed)\n",
        "history_cross_cohen_kag = 'cv_cohen_kag'\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in cv.split(cohen_kag_x_dataset):\n",
        "  X_train, y_train = cohen_kag_x_dataset[train_index], cohen_kag_y_dataset[train_index]\n",
        "  X_val, y_val = cohen_kag_x_dataset[val_index], cohen_kag_y_dataset[val_index]\n",
        "\n",
        "  model = tf.keras.models.Sequential(high_level_low_level_model+\n",
        "                                    [tf.keras.layers.Dense(classes_number, activation='softmax')], name=\"low_level_high_level\")\n",
        "\n",
        "  output_path = os.path.join(experiments_path, f\"{history_cross_cohen_kag}_iteration_{i}_{model.name}\")\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)\n",
        "  model.save(output_path, save_format='h5')\n",
        "  df = pd.DataFrame(history.history)\n",
        "  df.to_csv(f\"{output_path}.csv\")\n",
        "  i+= 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c17O4v23ezKK"
      },
      "source": [
        "##### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjLVovjle4w7",
        "outputId": "a0224e85-cef9-4e30-aed9-ac935fc69497"
      },
      "outputs": [],
      "source": [
        "cohen_kag_x_dataset = np.concatenate((cohen_x_dataset, kag_x_train, kag_x_val, kag_x_test))\n",
        "cohen_kag_y_dataset = np.concatenate((cohen_y_dataset, kag_y_train, kag_y_val, kag_y_test))\n",
        "cohen_kag_y_dataset = cohen_kag_y_dataset.reshape(cohen_kag_y_dataset.shape[0], cohen_kag_y_dataset.shape[1])\n",
        "\n",
        "cohen_kag_x_dataset, X_test, cohen_kag_y_dataset, y_test = sklearn.model_selection.train_test_split(cohen_kag_x_dataset, cohen_kag_y_dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "cv = sklearn.model_selection.ShuffleSplit(n_splits=5, train_size=0.78, random_state=seed)\n",
        "history_cross_cohen_kag = 'cv_cohen_kag'\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in cv.split(cohen_kag_x_dataset):\n",
        "  X_train, y_train = cohen_kag_x_dataset[train_index], cohen_kag_y_dataset[train_index]\n",
        "  X_val, y_val = cohen_kag_x_dataset[val_index], cohen_kag_y_dataset[val_index]\n",
        "\n",
        "  X_train = np.concatenate((X_train, X_train, X_train), axis=-1)\n",
        "  X_val = np.concatenate((X_val, X_val, X_val), axis=-1)\n",
        "\n",
        "  model = tf.keras.models.Sequential(resnet50, name=\"resnet50\")\n",
        "\n",
        "  output_path = os.path.join(experiments_path, f\"{history_cross_cohen_kag}_iteration_{i}_{model.name}\")\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)\n",
        "  model.save(output_path, save_format='h5')\n",
        "  df = pd.DataFrame(history.history)\n",
        "  df.to_csv(f\"{output_path}.csv\")\n",
        "  i+= 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmMHD64Guhh-"
      },
      "source": [
        "#### AP, PA e AP supine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6FptYwbukXS"
      },
      "outputs": [],
      "source": [
        "cohen_x_train, cohen_x_test, cohen_y_train, cohen_y_test = sklearn.model_selection.train_test_split(cohen_x_dataset, cohen_y_dataset, test_size=0.1, random_state=seed)\n",
        "cohen_x_train, cohen_x_val, cohen_y_train, cohen_y_val = sklearn.model_selection.train_test_split(cohen_x_train, cohen_y_train, train_size=0.78, random_state=seed)\n",
        "\n",
        "X_train = np.concatenate((cohen_x_train, kag_x_train))\n",
        "X_val = np.concatenate((cohen_x_val, kag_x_val))\n",
        "\n",
        "y_train = np.concatenate((cohen_y_train, kag_y_train))\n",
        "y_train =  y_train.reshape(y_train.shape[0], y_train.shape[1])\n",
        "\n",
        "y_val = np.concatenate((cohen_y_val, kag_y_val))\n",
        "y_val =  y_val.reshape(y_val.shape[0], y_val.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fRA3GIMHlTz"
      },
      "source": [
        "Larger regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W4tFXG4Hqh_",
        "outputId": "125bf263-55e4-4a93-8d55-04c6bc9a6f04"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential(different_segments_model+\n",
        "                                    [tf.keras.layers.Dense(classes_number, activation='softmax')], name=\"larger_regions\")\n",
        "\n",
        "history_view_split_cohen_kag = 'view_split_cohen_kag'\n",
        "output_path = os.path.join(experiments_path, f\"{history_view_split_cohen_kag}_{model.name}\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Pg2ItJI4N3"
      },
      "source": [
        "Low-level to high-level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdP1Vg53I_Xp",
        "outputId": "af8cab80-4232-4604-8a9d-cd887f3b5fea"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential(high_level_low_level_model+\n",
        "                                    [tf.keras.layers.Dense(classes_number, activation='softmax')], name=\"low_level_high_level\")\n",
        "\n",
        "history_view_split_cohen_kag = 'view_split_cohen_kag'\n",
        "output_path = os.path.join(experiments_path, f\"{history_view_split_cohen_kag}_{model.name}\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dCbbCSVJQ8d"
      },
      "source": [
        "Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH2tv_nXJSM3",
        "outputId": "2c210382-9b25-4e04-82fc-cbcc5eb1837f"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential(resnet50, name=\"resnet50\")\n",
        "\n",
        "# Converter os dados para 3 canais\n",
        "X_train = np.concatenate((X_train, X_train, X_train), axis=-1)\n",
        "X_val = np.concatenate((X_val, X_val, X_val), axis=-1)\n",
        "\n",
        "history_view_split_cohen_kag = 'view_split_cohen_kag'\n",
        "output_path = os.path.join(experiments_path, f\"{history_view_split_cohen_kag}_{model.name}\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVLrOGuFJTyK"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEO3KM_-JUxQ"
      },
      "outputs": [],
      "source": [
        "model.save(output_path, save_format='h5')\n",
        "df = pd.DataFrame(history.history)\n",
        "df.to_csv(os.path.join(experiments_path, f\"{history_view_split_cohen_kag}_{model.name}.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhEKDm1O1WDf"
      },
      "source": [
        "#### Cross-validation AP, PA e AP supine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8N8tzIb1YUO"
      },
      "outputs": [],
      "source": [
        "kag_test_dir = os.path.join(kag_dir, \"val\")\n",
        "kag_x_test = []\n",
        "kag_y_test = []\n",
        "\n",
        "for finding in os.listdir(kag_val_dir):\n",
        "  finding_path = os.path.join(kag_val_dir, finding)\n",
        "  for image in os.listdir(finding_path):\n",
        "    with PIL.Image.open(os.path.join(finding_path, image)) as img:\n",
        "      img_resized = img.convert('L')\n",
        "      img_resized = img_resized.resize((img_width, img_height))\n",
        "      kag_x_test.append(np.reshape(np.asarray(img_resized), (img_width, img_height, 1)))\n",
        "\n",
        "    if finding == 'NORMAL':\n",
        "      kag_y_test.append(ohe.transform([le.transform(['kag_normal'])]).reshape(len(le_categories), 1))\n",
        "    else:\n",
        "      label = find_class_label(image)\n",
        "      kag_y_test.append(ohe.transform([le.transform([f'kag_pneumonia_{label}'])]).reshape(len(le_categories), 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFelv4652Jfn"
      },
      "source": [
        "##### Larger regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLioG0UY2LK9",
        "outputId": "048e1904-465a-4a7a-c07a-840d4febb3d7"
      },
      "outputs": [],
      "source": [
        "cohen_kag_x_dataset = np.concatenate((cohen_x_dataset, kag_x_train, kag_x_val, kag_x_test))\n",
        "cohen_kag_y_dataset = np.concatenate((cohen_y_dataset, kag_y_train, kag_y_val, kag_y_test))\n",
        "cohen_kag_y_dataset = cohen_kag_y_dataset.reshape(cohen_kag_y_dataset.shape[0], cohen_kag_y_dataset.shape[1])\n",
        "\n",
        "cohen_kag_x_dataset, X_test, cohen_kag_y_dataset, y_test = sklearn.model_selection.train_test_split(cohen_kag_x_dataset, cohen_kag_y_dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "cv = sklearn.model_selection.ShuffleSplit(n_splits=5, train_size=0.78, random_state=seed)\n",
        "history_cross_cohen_kag = 'view_split_cv_cohen_kag'\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in cv.split(cohen_kag_x_dataset):\n",
        "  X_train, y_train = cohen_kag_x_dataset[train_index], cohen_kag_y_dataset[train_index]\n",
        "  X_val, y_val = cohen_kag_x_dataset[val_index], cohen_kag_y_dataset[val_index]\n",
        "\n",
        "  model = tf.keras.models.Sequential(different_segments_model+\n",
        "                                    [tf.keras.layers.Dense(classes_number, activation='softmax')], name=\"larger_regions\")\n",
        "\n",
        "  output_path = os.path.join(experiments_path, f\"{history_cross_cohen_kag}_iteration_{i}_{model.name}\")\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)\n",
        "  model.save(output_path, save_format='h5')\n",
        "  df = pd.DataFrame(history.history)\n",
        "  df.to_csv(f\"{output_path}.csv\")\n",
        "  i+= 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59cCLoDPMtml"
      },
      "source": [
        "##### Low-level to high-level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsu02Ti_MuBe",
        "outputId": "6af9e3a3-d01b-422a-8f1d-96db65672039"
      },
      "outputs": [],
      "source": [
        "cohen_kag_x_dataset = np.concatenate((cohen_x_dataset, kag_x_train, kag_x_val, kag_x_test))\n",
        "cohen_kag_y_dataset = np.concatenate((cohen_y_dataset, kag_y_train, kag_y_val, kag_y_test))\n",
        "cohen_kag_y_dataset = cohen_kag_y_dataset.reshape(cohen_kag_y_dataset.shape[0], cohen_kag_y_dataset.shape[1])\n",
        "\n",
        "cohen_kag_x_dataset, X_test, cohen_kag_y_dataset, y_test = sklearn.model_selection.train_test_split(cohen_kag_x_dataset, cohen_kag_y_dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "cv = sklearn.model_selection.ShuffleSplit(n_splits=5, train_size=0.78, random_state=seed)\n",
        "history_cross_cohen_kag = 'view_split_cv_cohen_kag'\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in cv.split(cohen_kag_x_dataset):\n",
        "  X_train, y_train = cohen_kag_x_dataset[train_index], cohen_kag_y_dataset[train_index]\n",
        "  X_val, y_val = cohen_kag_x_dataset[val_index], cohen_kag_y_dataset[val_index]\n",
        "\n",
        "  model = tf.keras.models.Sequential(high_level_low_level_model+\n",
        "                                    [tf.keras.layers.Dense(classes_number, activation='softmax')], name=\"low_level_high_level\")\n",
        "\n",
        "  output_path = os.path.join(experiments_path, f\"{history_cross_cohen_kag}_iteration_{i}_{model.name}\")\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)\n",
        "  model.save(output_path, save_format='h5')\n",
        "  df = pd.DataFrame(history.history)\n",
        "  df.to_csv(f\"{output_path}.csv\")\n",
        "  i+= 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl9thCybRhc8"
      },
      "source": [
        "##### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2ujlh5hRkXN",
        "outputId": "2f0cb763-1b03-4eb6-b383-f3c2f1d7d028"
      },
      "outputs": [],
      "source": [
        "cohen_kag_x_dataset = np.concatenate((cohen_x_dataset, kag_x_train, kag_x_val, kag_x_test))\n",
        "cohen_kag_y_dataset = np.concatenate((cohen_y_dataset, kag_y_train, kag_y_val, kag_y_test))\n",
        "cohen_kag_y_dataset = cohen_kag_y_dataset.reshape(cohen_kag_y_dataset.shape[0], cohen_kag_y_dataset.shape[1])\n",
        "\n",
        "cohen_kag_x_dataset, X_test, cohen_kag_y_dataset, y_test = sklearn.model_selection.train_test_split(cohen_kag_x_dataset, cohen_kag_y_dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "cv = sklearn.model_selection.ShuffleSplit(n_splits=5, train_size=0.78, random_state=seed)\n",
        "history_cross_cohen_kag = 'view_split_cv_cohen_kag'\n",
        "i = 0\n",
        "\n",
        "for train_index, val_index in cv.split(cohen_kag_x_dataset):\n",
        "  X_train, y_train = cohen_kag_x_dataset[train_index], cohen_kag_y_dataset[train_index]\n",
        "  X_val, y_val = cohen_kag_x_dataset[val_index], cohen_kag_y_dataset[val_index]\n",
        "\n",
        "  X_train = np.concatenate((X_train, X_train, X_train), axis=-1)\n",
        "  X_val = np.concatenate((X_val, X_val, X_val), axis=-1)\n",
        "\n",
        "  model = tf.keras.models.Sequential(resnet50, name=\"resnet50\")\n",
        "\n",
        "  output_path = os.path.join(experiments_path, f\"{history_cross_cohen_kag}_iteration_{i}_{model.name}\")\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs)\n",
        "  model.save(output_path, save_format='h5')\n",
        "  df = pd.DataFrame(history.history)\n",
        "  df.to_csv(f\"{output_path}.csv\")\n",
        "  i+= 1\n",
        "  gc.collect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "B9uybuRsSD85",
        "_eD5ZAcqVg10",
        "sxOBp6y1ED9D",
        "QtJPK8Ezcovw",
        "7jkiegIKfpHl",
        "B7fCuM_IwMxV",
        "lX0foXrTtapT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
